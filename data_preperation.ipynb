{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9f9751c",
   "metadata": {},
   "source": [
    "# Deep Learning group assignment\n",
    "Group name: Angry Birds\n",
    "\n",
    "Group members:\n",
    "- Nienke Reijnen: 2117034\n",
    "- Andrea Ciavatti: 2115635\n",
    "- Niels Boonstra: 1451294\n",
    "- Yannick Lankhorst: 2052754\n",
    "- Thom Zoomer:2059225\n",
    "- Anne Barnasconi: 2053988"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc615d47",
   "metadata": {},
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d1df5d",
   "metadata": {},
   "source": [
    "Before running, make sure to also have installed the following packages (according to lab 8 instructions):\n",
    "- pip install imageio\n",
    "- pip install future\n",
    "- pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b751e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c0a3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu, CPU\n"
     ]
    }
   ],
   "source": [
    "device, device_name = (torch.device(\"cuda\"), torch.cuda.get_device_name(0)) if torch.cuda.is_available() else (torch.device(\"cpu\"), \"CPU\")\n",
    "print(f\"Device: {device}, {device_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0f9ca2",
   "metadata": {},
   "source": [
    "## Data loading & preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac0c073",
   "metadata": {},
   "source": [
    "- Correct implementation of data loaders for images and annotations for your specific object detection model\n",
    "- Use of data augmentation techniques\n",
    "- Appropriate shuffling  and batching of data\n",
    "- Conduct an online search for relevant open-source datasets, and if you can find them, use them in your application as additional training data (to improve generalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9182d00",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c519cd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "### Defining transformations ###\n",
    "################################\n",
    "\n",
    "transform = None # here we define transforms we want to apply when loading the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8585276",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "### Defining a CustomDataset class ###\n",
    "######################################\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_path, transform):\n",
    "        \"\"\"\n",
    "        Initialize the custom dataset.\n",
    "        Works for both the train data and the test data.\n",
    "        \"\"\"\n",
    "        self.images_dir = os.path.join(data_path, \"images\")\n",
    "        self.transform = transform\n",
    "        annotations_file = data_path + \"/annotations.json\"\n",
    "        with open(annotations_file, 'r') as f:\n",
    "            annotations_list = json.load(f)\n",
    "       \n",
    "        # We need to extract the bounding boxes of the annotations from the JSON file and store them as [x_min, y_min, x_max, y_max] tensors\n",
    "        self.data = []\n",
    "        for entry in annotations_list:\n",
    "            image_name = entry['OriginalFileName']\n",
    "            annotation_data = entry['AnnotationData']\n",
    "            bird_boxes = self.extract_bird_boxes(annotation_data)\n",
    "            self.data.append({'imagename': image_name, 'bird_boxes_tensor': bird_boxes})\n",
    "\n",
    "        # Note: we should not load all the images into a tensor here, as it would take too much memory. We load images into a tensor in the __getitem__ method.\n",
    "\n",
    "\n",
    "    def extract_bird_boxes(self, annotation_data):\n",
    "        \"\"\"\n",
    "        Extract the coordinates of the birds from the annotation data in the JSON file and return it as a tensor.\n",
    "        \"\"\"\n",
    "        bird_boxes = []\n",
    "        for entry in annotation_data:\n",
    "            if entry['Label'] == 'Bird':\n",
    "                coordinates_list = entry['Coordinates']\n",
    "                x_coordinates = [point['X'] for point in coordinates_list]\n",
    "                y_coordinates = [point['Y'] for point in coordinates_list]\n",
    "                x_min, x_max = min(x_coordinates), max(x_coordinates)\n",
    "                y_min, y_max = min(y_coordinates), max(y_coordinates)\n",
    "                bird_boxes.append([x_min, y_min, x_max, y_max])\n",
    "\n",
    "        return torch.tensor(bird_boxes, dtype=torch.float32) # Shape: (num_birds, 4)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the size of the dataset, i.e. the number of images.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Load an image and its corresponding annotations.\n",
    "        \"\"\"\n",
    "        item = self.data[index]\n",
    "        image_path = os.path.join(self.images_dir, item['imagename'])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        # If we are using data augmentations, we should apply them here:\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, item['bird_boxes_tensor']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e4cc266",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_data_path = \"scarecrow_dataset/train\"\n",
    "test_data_path = \"scarecrow_dataset/test\"\n",
    "\n",
    "train_data = CustomDataset(\"scarecrow_dataset/train\", transform)\n",
    "test_data = CustomDataset(\"scarecrow_dataset/test\", transform)\n",
    "train_data, valid_data = torch.utils.data.random_split(train_data, [0.8, 0.2])\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(valid_data, batch_size=batch_size)\n",
    "test_loader  = DataLoader(test_data, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
